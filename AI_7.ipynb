{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRYc7VvRV-sW"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnJ05WrHZC1q"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.TPUStrategy(tpu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMhGQfnpaXRp"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import cifar100\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import utils as np_utils\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# load the CIFAR-100 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode='fine')\n",
        "\n",
        "# split the training dataset into sub-training set and validation set\n",
        "x_train_sub, x_val, y_train_sub, y_val = train_test_split(x_train, y_train, test_size=0.15, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hh7ehQoadAwZ"
      },
      "outputs": [],
      "source": [
        "y_train_sub = to_categorical(y_train_sub, num_classes=100)\n",
        "y_val = to_categorical(y_val, num_classes=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTTOUICUbRVq"
      },
      "outputs": [],
      "source": [
        "num_classes = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lj_fWic3bXFW"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.optimizers import Adam,SGD\n",
        "\n",
        "def create_model(activation, optimizer, filters, kernel_size, pool_size, dropout_rate):\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(filters, kernel_size=kernel_size, activation=activation, padding='same', input_shape=x_train_sub.shape[1:]))\n",
        "    model.add(Conv2D(filters, kernel_size=kernel_size, activation=activation, padding='same'))\n",
        "    model.add(MaxPooling2D(pool_size=pool_size))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Conv2D(filters*2, kernel_size=kernel_size, activation=activation, padding='same'))\n",
        "    model.add(Conv2D(filters*2, kernel_size=kernel_size, activation=activation, padding='same'))\n",
        "    model.add(MaxPooling2D(pool_size=pool_size))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512, activation=activation))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    \n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tu1M8-lbf6b"
      },
      "outputs": [],
      "source": [
        "activations = ['relu', 'tanh']\n",
        "optimizers = [Adam(learning_rate=1e-3), Adam(learning_rate=1e-4),SGD(learning_rate=0.001)]\n",
        "filters_list = [64,128,256]\n",
        "kernel_sizes = [(3, 3), (5, 5)]\n",
        "pool_sizes = [(2, 2), (3, 3)]\n",
        "dropout_rates = [0.25,0.3, 0.5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nj3Bk-mEb8GX"
      },
      "outputs": [],
      "source": [
        "models = []\n",
        "for activation in activations:\n",
        "    for optimizer in optimizers:\n",
        "        for filters in filters_list:\n",
        "            for kernel_size in kernel_sizes:\n",
        "                for pool_size in pool_sizes:\n",
        "                    for dropout_rate in dropout_rates:\n",
        "                        with tpu_strategy.scope():# creating the model in the TPUStrategy scope means we will train the model on the TPU\n",
        "                          model = create_model(activation, optimizer, filters, kernel_size, pool_size, dropout_rate)\n",
        "                          history = model.fit(x_train_sub, y_train_sub, batch_size=32, epochs=20, validation_data=(x_val, y_val),verbose=1)\n",
        "                          val_loss, val_acc = model.evaluate(x_val, y_val, verbose=0)\n",
        "                          models.append({\n",
        "                          'activation': activation,\n",
        "                          'optimizer': optimizer.get_config()['name'],\n",
        "                          'filters': filters,\n",
        "                          'kernel_size': kernel_size,\n",
        "                          'pool_size': pool_size,\n",
        "                          'dropout_rate': dropout_rate,\n",
        "                          'val_loss': val_loss,\n",
        "                          'val_acc': val_acc,\n",
        "                          'params': model.count_params(),\n",
        "                          'history': history\n",
        "                      })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5d1yJr-cN0f"
      },
      "outputs": [],
      "source": [
        "models.sort(key=lambda x: x['val_acc'], reverse=True)\n",
        "\n",
        "\n",
        "top_models = models[:3]\n",
        "for i, model in enumerate(top_models):\n",
        "    print(f'Top {i+1} Model:')\n",
        "    print('Activation:', model['activation'])\n",
        "    print('Optimizer:', model['optimizer'])\n",
        "    print('Filters:', model['filters'])\n",
        "    print('Kernel Size:', model['kernel_size'])\n",
        "    print('Pool Size:', model['pool_size'])\n",
        "    print('Dropout Rate:', model['dropout_rate'])\n",
        "    print('Validation Accuracy:', model['val_acc'])\n",
        "    print('Parameters:', model['params'])\n",
        "    print('-'*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWjRTK08cdUZ"
      },
      "outputs": [],
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "y_train = to_categorical(y_train, num_classes=num_classes)\n",
        "y_test = to_categorical(y_test, num_classes=num_classes)\n",
        "\n",
        "\n",
        "for i, model in enumerate(top_models):\n",
        "    print(f'Training Top {i+1} Model...')\n",
        "    model = create_model(model['activation'], model['optimizer'], model['filters'], model['kernel_size'], model['pool_size'], model['dropout_rate'])\n",
        "    history = model.fit(x_train, y_train, batch_size=32, epochs=20, validation_data=(x_test, y_test), verbose=0)\n",
        "    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "    model['test_acc'] = test_acc\n",
        "    model['history'] = history\n",
        "    print(f'Test Accuracy: {test_acc:.4f}')\n",
        "    print('-'*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSEndWrocgjM"
      },
      "outputs": [],
      "source": [
        "\n",
        "top_models.sort(key=lambda x: x['test_acc'], reverse=True)\n",
        "\n",
        "\n",
        "for i, model in enumerate(top_models):\n",
        "    print(f'Top {i+1} Model Test Accuracy: {model[\"test_acc\"]:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgBddPEZcg79"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}