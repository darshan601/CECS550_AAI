{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VCDdCCN_199C"
      },
      "outputs": [],
      "source": [
        "# Generating a toy dataset.\n",
        "# DO NOT MODIFY THIS PART\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "import random as rand\n",
        "\n",
        "paras = list((rand.random() - 0.5 for _ in range(9)))\n",
        "\n",
        "def y_gen(x):\n",
        "    h_11 = math.tanh(paras[0] * x[0] + paras[1] * x[1] + paras[2])\n",
        "    h_12 = math.tanh(paras[3] * x[0] + paras[4] * x[1] + paras[5])\n",
        "    h_21 = 1/(1 + np.exp(-(paras[6] * h_11 + paras[7] * h_12 + paras[8])))\n",
        "    return h_21 + ((rand.random()-0.5)/100 if rand.random()>0.6 else 0)\n",
        "\n",
        "n = 300\n",
        "x = list(zip((rand.random() - 0.5 for _ in range(n)), (rand.random() - 0.5 for _ in range(n))))\n",
        "y = list(map(y_gen, x))\n",
        "y = [(i-min(y))/(max(y)-min(y)) for i in y]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xWyljReu199E"
      },
      "outputs": [],
      "source": [
        "# Spliting dataset into training, validation, and test.\n",
        "# DO NOT MODIFY THIS PART\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "r = 0.25\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=r)\n",
        "\n",
        "x_val = x_train[:int(n*r)]\n",
        "partial_x_train = x_train[int(n*r):]\n",
        "y_val = y_train[:int(n*r)]\n",
        "partial_y_train = y_train[int(n*r):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "B1td-EhoIB3N"
      },
      "outputs": [],
      "source": [
        "# DO NOT MODIFY THIS PART\n",
        "\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "\n",
        "def create_model(learning_rate=0.01, beta_1=0.9, beta_2=0.999):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Dense(2, activation='tanh', input_shape=(2,)))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer=optimizers.Adam(learning_rate=learning_rate, beta_1=beta_1, beta_2=beta_2), loss='mse')\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHYumU4N199E",
        "outputId": "8c6f045a-0a3f-4d29-e3ab-3c295def1e21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-c49ce1ce4947>:6: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  model=KerasRegressor(create_model)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0325\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.0253\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0338\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0474\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0164\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0214\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0409\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0415\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0396\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0297\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0160\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0227\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0359\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0251\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0506\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.0441\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0312\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0428\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0570\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0438\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0201\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0297\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0468\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0206\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0167\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0273\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0289\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0426\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0208\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0145\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0551\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0283\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0442\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0463\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0155\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0178\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0390\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0475\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0589\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0355\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0163\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0230\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.0311\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0431\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0327\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0482\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0323\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0432\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0842\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0594\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0415\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0328\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0303\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0232\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0219\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0449\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0266\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0379\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0297\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0111\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0276\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0399\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0571\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0351\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0113\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0278\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0243\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0479\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0455\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0201\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0186\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0265\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0243\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0391\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0240\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0249\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0372\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0562\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0334\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0453\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0465\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0303\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.0281\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0496\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0162\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0236\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0325\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0269\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0277\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0184\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0408\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0449\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0240\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0409\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0390\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0312\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0218\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0730\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0230\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0374\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0220\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0347\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0223\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0170\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0165\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0453\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0306\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0439\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0437\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0382\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0396\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0596\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0248\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0197\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0390\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0172\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0379\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0253\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0321\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0125\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0265\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0339\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0303\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 0.0325\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0166\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0281\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0394\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0416\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0285\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0471\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0190\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0268\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0419\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0373\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0298\n",
            "-0.031065116077661513 {'beta_1': 0.9, 'beta_2': 0.999, 'learning_rate': 0.001}\n",
            "-0.03461373783648014 {'beta_1': 0.9, 'beta_2': 0.999, 'learning_rate': 0.01}\n",
            "-0.030035848170518874 {'beta_1': 0.9, 'beta_2': 0.999, 'learning_rate': 0.1}\n",
            "-0.04378613755106926 {'beta_1': 0.9, 'beta_2': 0.99, 'learning_rate': 0.001}\n",
            "-0.02677816115319729 {'beta_1': 0.9, 'beta_2': 0.99, 'learning_rate': 0.01}\n",
            "-0.026819914020597933 {'beta_1': 0.9, 'beta_2': 0.99, 'learning_rate': 0.1}\n",
            "-0.03787997551262379 {'beta_1': 0.9, 'beta_2': 0.9, 'learning_rate': 0.001}\n",
            "-0.039749518036842346 {'beta_1': 0.9, 'beta_2': 0.9, 'learning_rate': 0.01}\n",
            "-0.02923990935087204 {'beta_1': 0.9, 'beta_2': 0.9, 'learning_rate': 0.1}\n",
            "-0.05348254889249802 {'beta_1': 0.8, 'beta_2': 0.999, 'learning_rate': 0.001}\n",
            "-0.029971014708280563 {'beta_1': 0.8, 'beta_2': 0.999, 'learning_rate': 0.01}\n",
            "-0.03003972191363573 {'beta_1': 0.8, 'beta_2': 0.999, 'learning_rate': 0.1}\n",
            "-0.03419818896800279 {'beta_1': 0.8, 'beta_2': 0.99, 'learning_rate': 0.001}\n",
            "-0.03311084918677807 {'beta_1': 0.8, 'beta_2': 0.99, 'learning_rate': 0.01}\n",
            "-0.02650867886841297 {'beta_1': 0.8, 'beta_2': 0.99, 'learning_rate': 0.1}\n",
            "-0.039394908025860785 {'beta_1': 0.8, 'beta_2': 0.9, 'learning_rate': 0.001}\n",
            "-0.03413953147828579 {'beta_1': 0.8, 'beta_2': 0.9, 'learning_rate': 0.01}\n",
            "-0.02581307142972946 {'beta_1': 0.8, 'beta_2': 0.9, 'learning_rate': 0.1}\n",
            "-0.03790958970785141 {'beta_1': 0.7, 'beta_2': 0.999, 'learning_rate': 0.001}\n",
            "-0.03727486245334148 {'beta_1': 0.7, 'beta_2': 0.999, 'learning_rate': 0.01}\n",
            "-0.02249470166862011 {'beta_1': 0.7, 'beta_2': 0.999, 'learning_rate': 0.1}\n",
            "-0.040310940518975255 {'beta_1': 0.7, 'beta_2': 0.99, 'learning_rate': 0.001}\n",
            "-0.036547097563743594 {'beta_1': 0.7, 'beta_2': 0.99, 'learning_rate': 0.01}\n",
            "-0.02499274257570505 {'beta_1': 0.7, 'beta_2': 0.99, 'learning_rate': 0.1}\n",
            "-0.027973619848489763 {'beta_1': 0.7, 'beta_2': 0.9, 'learning_rate': 0.001}\n",
            "-0.03695185035467148 {'beta_1': 0.7, 'beta_2': 0.9, 'learning_rate': 0.01}\n",
            "-0.030940166860818862 {'beta_1': 0.7, 'beta_2': 0.9, 'learning_rate': 0.1}\n",
            "best parameters {'beta_1': 0.7, 'beta_2': 0.999, 'learning_rate': 0.1}\n",
            "mse -0.02249470166862011\n"
          ]
        }
      ],
      "source": [
        "# Complete the cell to find a best hyper-parameter setting using GridSerachCV\n",
        "\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "model=KerasRegressor(create_model)\n",
        "\n",
        "learning_rate={'learning_rate':[0.001,0.01,0.1],'beta_2':[0.999,0.99,0.9],'beta_1':[0.9,0.8,0.7]}\n",
        "\n",
        "grid=GridSearchCV(model,learning_rate)\n",
        "\n",
        "grid_result=grid.fit(partial_x_train,partial_y_train,validation_data=(x_val,y_val),verbose=0)\n",
        "\n",
        "for i in range(len(grid_result.cv_results_[\"params\"])):\n",
        "  print(grid_result.cv_results_[\"mean_test_score\"][i],grid_result.cv_results_[\"params\"][i])\n",
        "\n",
        "print(\"best parameters\",grid_result.best_params_)\n",
        "\n",
        "print(\"mse\",grid_result.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s_fwJUxL3Li7"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NvleqM7k4HMH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}